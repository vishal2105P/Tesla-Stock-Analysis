# -*- coding: utf-8 -*-
"""Tesla Stock Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zHb8IImNPYbw_bVRzxuCc9pWwxAzUG1u
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import xgboost as XGBRegressor
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv("/content/TESLA.csv")

print("Dataset Shape:", df.shape)
print("\nFirst few rows:")
print(df.head())
print("\nData Info:")
print(df.info())
print("\nMissing Values:")
print(df.isnull().sum())

def preprocess_data(df):
    # Convert Date to datetime
    df['Date'] = pd.to_datetime(df['Date'])

    # Create time-based features
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Day'] = df['Date'].dt.day
    df['DayOfWeek'] = df['Date'].dt.dayofweek

    # Calculate technical indicators
    df['MA7'] = df['Close'].rolling(window=7).mean()
    df['MA30'] = df['Close'].rolling(window=30).mean()
    df['MA90'] = df['Close'].rolling(window=90).mean()

    # Calculate price changes
    df['Price_Change'] = df['Close'].pct_change()
    df['Volume_Change'] = df['Volume'].pct_change()

    # Calculate volatility
    df['Volatility'] = df['Price_Change'].rolling(window=30).std()

    # Drop missing values
    df = df.dropna()
    return df

def create_features(df):
    # Create target variable (next day's closing price)
    df['Target'] = df['Close'].shift(-1)

    # Select features for modeling
    features = ['Open', 'High', 'Low', 'Close', 'Volume', 'MA7', 'MA30', 'MA90',
                'Price_Change', 'Volume_Change', 'Volatility', 'Year', 'Month', 'Day', 'DayOfWeek']

    # Prepare X and y
    X = df[features].iloc[:-1]  # Remove last row since we don't have target for it
    y = df['Target'].iloc[:-1]

    return X, y

def train_evaluate_models(X, y):
    # Split data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Scale features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Initialize models
    models = {
        'Linear Regression': LinearRegression(),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'XGBoost': XGBRegressor.XGBRegressor(n_estimators=100, random_state=42)
    }

    results = {}
    predictions = {}

    # Train and evaluate each model
    for name, model in models.items():
        # Train model
        model.fit(X_train_scaled, y_train)

        # Make predictions
        train_pred = model.predict(X_train_scaled)
        test_pred = model.predict(X_test_scaled)
        predictions[name] = test_pred

        # Calculate metrics
        results[name] = {
            'Train R2': r2_score(y_train, train_pred),
            'Test R2': r2_score(y_test, test_pred),
            'Train RMSE': np.sqrt(mean_squared_error(y_train, train_pred)),
            'Test RMSE': np.sqrt(mean_squared_error(y_test, test_pred)),
            'Train MAE': mean_absolute_error(y_train, train_pred),
            'Test MAE': mean_absolute_error(y_test, test_pred)
        }

    return results, predictions, y_test, X_test.index

def plot_stock_trends(df):
    plt.figure(figsize=(15, 10))

    # Plot stock prices
    plt.subplot(2, 1, 1)
    plt.plot(df['Date'], df['Close'], label='Close Price')
    plt.plot(df['Date'], df['MA7'], label='7-day MA')
    plt.plot(df['Date'], df['MA30'], label='30-day MA')
    plt.plot(df['Date'], df['MA90'], label='90-day MA')
    plt.title('Tesla Stock Price Trends')
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.legend()

    # Plot volume
    plt.subplot(2, 1, 2)
    plt.bar(df['Date'], df['Volume'], alpha=0.5)
    plt.title('Trading Volume')
    plt.xlabel('Date')
    plt.ylabel('Volume')

    plt.tight_layout()
    plt.show()
def plot_model_predictions(predictions, y_test, test_dates):
    plt.figure(figsize=(15, 6))
    plt.plot(test_dates, y_test, label='Actual', alpha=0.7)

    for name, pred in predictions.items():
        plt.plot(test_dates, pred, label=f'{name} Predictions', alpha=0.7)

    plt.title('Model Predictions vs Actual Prices')
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def plot_correlation_matrix(df):
    plt.figure(figsize=(12, 8))
    correlation_matrix = df[['Open', 'High', 'Low', 'Close', 'Volume', 'MA7', 'MA30', 'MA90']].corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('Correlation Matrix of Features')
    plt.tight_layout()
    plt.show()
    # Main execution pipeline
def run_analysis(df):
    # Preprocess data
    processed_df = preprocess_data(df)

    # Create features
    X, y = create_features(processed_df)

    # Train and evaluate models
    results, predictions, y_test, test_dates = train_evaluate_models(X, y)

    # Generate visualizations
    plot_stock_trends(processed_df)
    plot_correlation_matrix(processed_df)
    plot_model_predictions(predictions, y_test, test_dates)

    # Print model evaluation metrics
    print("\nModel Evaluation Metrics:")
    for model_name, metrics in results.items():
        print(f"\n{model_name}:")
        for metric_name, value in metrics.items():
            print(f"{metric_name}: {value:.4f}")

    return results, predictions, processed_df

results, predictions, processed_df = run_analysis(df)